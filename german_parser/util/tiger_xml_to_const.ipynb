{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from const import CONSTS\n",
    "from util import get_int_after_underscore, get_str_after_underscore, is_pairwise_disjoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from pydantic import BaseModel, root_validator, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = ET.parse(open(f\"{CONSTS['data_dir']}/tiger/tiger_2.2_utf8.xml\", \"r\", encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Terminal(BaseModel):\n",
    "    word: str = Field()\n",
    "    lemma: str = Field()\n",
    "    pos: str = Field()\n",
    "    morph: str = Field()\n",
    "    case: str = Field()\n",
    "    number: str = Field()\n",
    "    gender: str = Field()\n",
    "    person: str = Field()\n",
    "    degree: str = Field()\n",
    "    tense: str = Field()\n",
    "    mood: str = Field()\n",
    "    \n",
    "    idx: int = Field()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "class Constituent(BaseModel):\n",
    "    id: int   = Field()    # node's id within the sentence\n",
    "    head: int | None = Field()    # node's head word TODO: remove None!!\n",
    "    yld: set[int] = Field()# node's yield\n",
    "    sym: str     = Field() # node's symbol\n",
    "\n",
    "    edge_label: str | None = Field(default=None) # the label for the edge from this constituent to its parent\n",
    "    parent: int | None = Field(default=None) # the id of the parent node\n",
    "\n",
    "    is_pre_terminal: bool = False\n",
    "    children: list[int] = Field(defualt=[])\n",
    "\n",
    "    @root_validator()\n",
    "    @classmethod\n",
    "    def _check_children_types(cls, field_values: dict[str, Any]):\n",
    "        # if \"children\" not in field_values.keys():\n",
    "        #     return field_values\n",
    "\n",
    "        # for child in field_values[\"children\"]:\n",
    "        #     if field_values[\"is_pre_terminal\"]:\n",
    "        #         assert isinstance(child, Terminal), \"Expected all children to be of type Terminal\"\n",
    "        #     else:\n",
    "        #         assert isinstance(child, cls), \"Expected all children to be of type Constituent\"\n",
    "        return field_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "    def __init__(self, tree_element: ET.Element):\n",
    "        self.head_rules = { 'S': [('s','HD',[])],\n",
    "                              'VP': [('s','HD',[])],\n",
    "                              'VZ': [('s','HD',[])],\n",
    "                              'AVP':[('s','HD',[]),('s','PH',[]),('r','AVC',['ADV']),('l','AVC',['FM'])],\n",
    "                              'AP': [('s','HD',[]),('s','PH',[])],\n",
    "                              'DL': [('s','DH',[])],\n",
    "                              'AA': [('s','HD',[])],\n",
    "                              'ISU':[('l','UC',[])],\n",
    "                              'PN': [('r','PNC',['NE','NN','FM','TRUNC','APPR','APPRART','CARD','VVFIN','VAFIN','ADJA','ADJD','XY'])],\n",
    "                              'MPN': [('r','PNC',['NE','NN','FM','TRUNC','APPR','APPRART','CARD','VVFIN','VAFIN','ADJA','ADJD','XY'])],\n",
    "                              'NM': [('r','NMC',['NN','CARD'])],\n",
    "                              'MTA':[('r','ADC',['ADJA'])],\n",
    "                              'PP': [('r','HD',['APPRART','APPR','APPO','PROAV','NE','APZR','PWAV','TRUNC']),('r','AC',['APPRART','APPR','APPO','PROAV','NE','APZR','PWAV','TRUNC']),('r','PH',['APPRART','APPR','APPO','PROAV','NE','APZR','PWAV','TRUNC']),('l','NK',['PROAV'])],\n",
    "                              'CH': [('s','HD',[]),('l','UC',['FM','NE','XY','CARD','ITJ'])],\n",
    "                              'NP': [('l','HD',['NN']),('l','NK',['NN']),('r','HD',['NE','PPER','PIS','PDS','PRELS','PRF','PWS','PPOSS','FM','TRUNC','ADJA','CARD','PIAT','PWAV','PROAV','ADJD','ADV','APPRART','PDAT']),('r','NK',['NE','PPER','PIS','PDS','PRELS','PRF','PWS','PPOSS','FM','TRUNC','ADJA','CARD','PIAT','PWAV','PROAV','ADJD','ADV','APPRART','PDAT']),('r','PH',['NN','NE','PPER','PIS','PDS','PRELS','PRF','PWS','PPOSS','FM','TRUNC','ADJA','CARD','PIAT','PWAV','PROAV','ADJD','ADV','APPRART','PDAT'])],              \n",
    "                              'CAC':[('l','CJ',[])],\n",
    "                              'CAP':[('l','CJ',[])],\n",
    "                             'CAVP':[('l','CJ',[])],\n",
    "                              'CCP':[('l','CJ',[])],\n",
    "                              'CNP':[('l','CJ',[])],\n",
    "                              'CO': [('l','CJ',[])],\n",
    "                              'CPP':[('l','CJ',[])],\n",
    "                              'CS': [('l','CJ',[])],\n",
    "                              'CVP':[('l','CJ',[])],\n",
    "                              'CVZ':[('l','CJ',[])]\n",
    "                            }\n",
    "        self.verb_phrase_reattach_symbols = [\"S\", \"VP\"]\n",
    "        self.constituents_to_ignore_heads = [\"VROOT\"]\n",
    "        \"\"\"\n",
    "        headrules is a dict[str, rules]\n",
    "        where rules is list[rule]\n",
    "        where rule is tuple[direction, edge_label, list[str]]\n",
    "            edge_label dictates the edge to follow\n",
    "            list[str] is a list of parts of speech to find along that edge\n",
    "            direction is one of 'l' or 'r' for left or right: if left, follow the edge to constituent that matches the first pos in the list, if right, follow the edge to the rightmost constituent that matches the pos\n",
    "        \"\"\"\n",
    "\n",
    "        # find elements in xml tree\n",
    "        self.tree_graph = tree_element.find(\"graph\")\n",
    "        self.tree_graph_root_name = get_str_after_underscore(self.tree_graph.attrib[\"root\"])\n",
    "        self.tree_terminals = self.tree_graph.find(\"terminals\")\n",
    "        self.tree_nonterminals = self.tree_graph.find(\"nonterminals\")\n",
    "\n",
    "        self.is_discontinuous = (\"discontinuous\" in self.tree_graph.attrib) and (self.tree_graph.attrib[\"discontinuous\"] == \"true\")\n",
    "\n",
    "        self.terminals: dict[int, Terminal] = {} # use dict for 1-based indexing\n",
    "        self.constituents: dict[int, Constituent] = {}\n",
    "\n",
    "        # parse terminals\n",
    "        for idx, t in enumerate(self.tree_terminals.iter(\"t\")):\n",
    "            assert idx + 1 == get_int_after_underscore(t.attrib[\"id\"]), f\"Terminal index '{idx + 1}' does not match index implied by its id '{t.attrib['id']}'\"\n",
    "            term = Terminal(**t.attrib, idx=idx + 1)\n",
    "            self.terminals.update({\n",
    "                idx + 1: term\n",
    "            })\n",
    "\n",
    "        # create pre-terminals from terminals: the pre-terminals are constituents with id equal to the terminal's index within the sentence\n",
    "        self.constituents.update({\n",
    "                t.idx: Constituent(\n",
    "                    id=t.idx,\n",
    "                    head=t.idx,\n",
    "                    yld={t.idx},\n",
    "                    sym=t.pos,\n",
    "                    is_pre_terminal=True,\n",
    "                    children=[t.idx]\n",
    "                )\n",
    "            for t in self.terminals.values()})\n",
    "        \n",
    "        self.integize_generator = self.integize()\n",
    "        integize_dict: dict[str, int] = {}\n",
    "\n",
    "        # create non-terminal constituents\n",
    "        for nt in self.tree_nonterminals.iter(\"nt\"):\n",
    "            nt_id = get_int_after_underscore(nt.attrib[\"id\"])\n",
    "            if nt_id is None:\n",
    "                nt_id = next(self.integize_generator)\n",
    "                assert nt_id not in integize_dict.values()\n",
    "                integize_dict[get_str_after_underscore(nt.attrib[\"id\"])] = nt_id\n",
    "            assert nt_id is not None\n",
    "\n",
    "            nt_sym = nt.attrib[\"cat\"]\n",
    "            nt_head = None # default to None\n",
    "\n",
    "            nt_children: list[tuple[str, int]] = [] # list of tuple[edge_label, child_id]\n",
    "\n",
    "            nt_edges = nt.iter(\"edge\")\n",
    "            for edge in nt_edges:\n",
    "                edge_id_ref = get_int_after_underscore(edge.attrib[\"idref\"], integize_dict.get(get_str_after_underscore(edge.attrib[\"idref\"]), None))\n",
    "                edge_label = edge.attrib[\"label\"]\n",
    "                assert edge_id_ref is not None\n",
    "                assert edge_id_ref in self.constituents\n",
    "\n",
    "                nt_children.append((edge_label, edge_id_ref))\n",
    "                if edge.attrib[\"label\"] == \"HD\":\n",
    "                    nt_head = edge_id_ref\n",
    "\n",
    "                # add edge label and parent id to child constituent\n",
    "                assert self.constituents[edge_id_ref].parent is None, f\"Constituent '{edge_id_ref}' already has a parent\"\n",
    "                assert self.constituents[edge_id_ref].edge_label is None, f\"Constituent '{edge_id_ref}' already has an edge label\"\n",
    "                self.constituents[edge_id_ref].parent = nt_id\n",
    "                self.constituents[edge_id_ref].edge_label = edge_label\n",
    "\n",
    "            nt_children_ylds = [self.constituents[c_id].yld for _, c_id in nt_children]\n",
    "            assert is_pairwise_disjoint(*nt_children_ylds), \"Yields of children nodes must be pairwise disjoint\"\n",
    "\n",
    "            self.constituents.update({\n",
    "                nt_id: Constituent(\n",
    "                    id=nt_id,\n",
    "                    sym=nt_sym,\n",
    "                    head=nt_head,\n",
    "                    is_pre_terminal=False,\n",
    "                    yld=set.union(*nt_children_ylds),\n",
    "                    children=[c_id for _, c_id in nt_children]\n",
    "                )\n",
    "            })\n",
    "        \n",
    "        # find root\n",
    "        try:\n",
    "            self.root = int(self.tree_graph_root_name)\n",
    "        except Exception:\n",
    "            self.root = integize_dict[self.tree_graph_root_name]\n",
    "    \n",
    "        assert self.constituents[self.root].yld == set(range(1, len(self.terminals) + 1)), f\"Root constituent must yield entire sentence\"\n",
    "\n",
    "        # attempt to find heads for all phrases that do not have a head already defined by the markup\n",
    "        empty_constituent_generator = self.create_next_empty_constituent()\n",
    "        constituents_without_heads = [c for c in self.constituents.values() if c.head is None and c.sym not in self.constituents_to_ignore_heads]\n",
    "        for c in constituents_without_heads:\n",
    "            if c.head is None:\n",
    "                c.head = self.find_head(c.id)\n",
    "\n",
    "                # reattach VP or S\n",
    "                if c.head is None and c.sym in self.verb_phrase_reattach_symbols:\n",
    "                    c.head = next(empty_constituent_generator)\n",
    "\n",
    "                print(f\"Found head word {c.head} for constituent {c.id}\")        \n",
    "\n",
    "    def find_head_candidates(self, children: list[int], edge_label: str, pos_list: list[str]):\n",
    "        children_matching_edge = [c for c in children if self.constituents[c].edge_label == edge_label]\n",
    "        assert set([v for c in children_matching_edge for v in self.constituents[c].yld]).issubset(set(self.terminals.keys())), \"Head candidates must be terminals\"\n",
    "\n",
    "        if len(children_matching_edge) > 1:\n",
    "            print(f\"Warning: {len(children_matching_edge)} candidate edges exist\")\n",
    "\n",
    "        if not pos_list: # if pos_list is empty, then we don't care about the POS of the head\n",
    "            yield [v for c in children_matching_edge for v in self.constituents[c].yld]\n",
    "        \n",
    "        for pos in pos_list:\n",
    "            yield [v for c in children_matching_edge for v in self.constituents[c].yld if self.constituents[v].sym == pos]\n",
    "\n",
    "    def integize(self):\n",
    "        num_integers = 1048576\n",
    "        while True:\n",
    "            num_integers += 1\n",
    "            yield num_integers\n",
    "\n",
    "    def create_next_empty_constituent(self):\n",
    "        \"\"\"\n",
    "        Creates an empty constituent and adds this to the sentence's constituent dict, yielding its id. Empty constituent ids are negative integers.\n",
    "        \"\"\"\n",
    "        num_empty_constituents = 0 # counter to keep empty constituent ids unique\n",
    "        while True:\n",
    "            num_empty_constituents -= 1\n",
    "            assert num_empty_constituents not in self.constituents, f\"Empty constituent id '{num_empty_constituents}' already exists\"\n",
    "\n",
    "            self.constituents.update({\n",
    "                num_empty_constituents: Constituent(\n",
    "                    id=num_empty_constituents,\n",
    "                    sym=\"<EMPTY>\",\n",
    "                    head=None,\n",
    "                    is_pre_terminal=True,\n",
    "                    yld=set(),\n",
    "                    children=[]\n",
    "                )\n",
    "            })\n",
    "\n",
    "            yield num_empty_constituents\n",
    "\n",
    "    def find_head(self, idx: int) -> int | None:\n",
    "        assert idx in self.constituents, f\"Constituent '{idx}' does not exist\"\n",
    "        assert self.constituents[idx].sym in self.head_rules, f\"Constituent symbol '{self.constituents[idx].sym}' has no head rules\"\n",
    "\n",
    "        for rule in self.head_rules.values():\n",
    "            for dir, label, pos_list in rule:\n",
    "                for head_candidates in self.find_head_candidates(self.constituents[idx].children, label, pos_list):\n",
    "                    if dir == 's' and head_candidates:\n",
    "                        assert len(head_candidates) == 1, \"'s' direction requires unique head candidate\"\n",
    "                        return head_candidates[0]\n",
    "                    elif dir == 'l' and head_candidates:\n",
    "                        return min(head_candidates)\n",
    "                    elif dir == 'r' and head_candidates:\n",
    "                        return max(head_candidates)\n",
    "                    \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found head word 1 for constituent 500\n",
      "Found head word 7 for constituent 503\n",
      "Found head word -1 for constituent 504\n"
     ]
    }
   ],
   "source": [
    "sent = Sentence(document.find('.//*[@id=\"s31\"]')) # type:ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_s = document.findall(\".//s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "errors = 0\n",
    "sents = []\n",
    "for idx, s in enumerate(all_s):\n",
    "    print(f\"Parsing sentence {idx + 1}; errors {errors}\")\n",
    "    try:\n",
    "        sents.append(Sentence(s))\n",
    "    except Exception:\n",
    "        errors += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: Constituent(id=1, head=1, yld={1}, sym='$(', edge_label='--', parent=1048577, is_pre_terminal=True, children=[1]),\n",
       " 2: Constituent(id=2, head=2, yld={2}, sym='NE', edge_label='PNC', parent=500, is_pre_terminal=True, children=[2]),\n",
       " 3: Constituent(id=3, head=3, yld={3}, sym='NE', edge_label='PNC', parent=500, is_pre_terminal=True, children=[3]),\n",
       " 4: Constituent(id=4, head=4, yld={4}, sym='VAFIN', edge_label='HD', parent=502, is_pre_terminal=True, children=[4]),\n",
       " 5: Constituent(id=5, head=5, yld={5}, sym='ADV', edge_label='MO', parent=502, is_pre_terminal=True, children=[5]),\n",
       " 6: Constituent(id=6, head=6, yld={6}, sym='ART', edge_label='NK', parent=501, is_pre_terminal=True, children=[6]),\n",
       " 7: Constituent(id=7, head=7, yld={7}, sym='ADJA', edge_label='NK', parent=501, is_pre_terminal=True, children=[7]),\n",
       " 8: Constituent(id=8, head=8, yld={8}, sym='NN', edge_label='NK', parent=501, is_pre_terminal=True, children=[8]),\n",
       " 9: Constituent(id=9, head=9, yld={9}, sym='$(', edge_label='--', parent=1048577, is_pre_terminal=True, children=[9]),\n",
       " 500: Constituent(id=500, head=3, yld={2, 3}, sym='PN', edge_label='SB', parent=502, is_pre_terminal=False, children=[2, 3]),\n",
       " 501: Constituent(id=501, head=8, yld={8, 6, 7}, sym='NP', edge_label='PD', parent=502, is_pre_terminal=False, children=[6, 7, 8]),\n",
       " 502: Constituent(id=502, head=4, yld={2, 3, 4, 5, 6, 7, 8}, sym='S', edge_label='--', parent=1048577, is_pre_terminal=False, children=[500, 4, 5, 501]),\n",
       " 1048577: Constituent(id=1048577, head=None, yld={1, 2, 3, 4, 5, 6, 7, 8, 9}, sym='VROOT', edge_label=None, parent=None, is_pre_terminal=False, children=[1, 502, 9])}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[0].constituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_lengths = [v for v in map(lambda v : len(v.terminals), sents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5221\n",
      "34835\n"
     ]
    }
   ],
   "source": [
    "for i, l in enumerate(sents_lengths):\n",
    "    if l == 130:\n",
    "        print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Sentence at 0x7ff274995690>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check behaviour if multiple candidate edges exist is expected: r means find largest index word (rightmost word)\n",
    "# TODO: check head rules satisfy definition of constituent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "german",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
