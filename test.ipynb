{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "from german_parser.model.words import WordCNN\n",
    "from german_parser.model.words import WordEmbedding\n",
    "\n",
    "from torch.utils.data import DataLoader, default_collate\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from german_parser.util.const import CONSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from german_parser.util.dataloader import TigerDatasetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:model:Parsing dataset from '/home/james/programming/ml/german/german_parser/util/../../data/tiger/tiger_2.2_utf8.xml'...\n",
      "INFO:model:Parsed 5047 sentences.\n",
      "INFO:model:Generating trees...\n",
      "INFO:model:4346 (86.11%) trees generated.\n",
      "INFO:model:Dataset split into 3042 training, 869 dev, and 435 test trees.\n"
     ]
    }
   ],
   "source": [
    "g = TigerDatasetGenerator(f\"{CONSTS['data_dir']}/tiger/tiger_2.2_utf8.xml\", (0.2, 0.1), prop_of_tiger_to_use=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = g.get_training_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_fn(x):\n",
    "    res = default_collate(x)\n",
    "    sentence_lenghts: torch.Tensor = res[1]\n",
    "    arg_sort = sentence_lenghts.argsort(descending=True)\n",
    "\n",
    "    return [r[arg_sort] for r in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=my_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class LSTM(nn.Module): # batch_first = True\n",
    "    def __init__(self, input_size, hidden_size, bidirectional=True, num_layers=1, dropout=0.2):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            input_size (_type_): _description_\n",
    "            hidden_size (_type_): _description_\n",
    "            bidirectional (bool, optional): _description_. Defaults to True.\n",
    "            num_layers (int, optional): _description_. Defaults to 1.\n",
    "            dropout (float, optional): _description_. Defaults to 0.2. Only applies to non-final layers (so no effect if num_layers = 1)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size   # E_in\n",
    "        self.hidden_size = hidden_size # H_in\n",
    "        self.num_layers = num_layers   # H_cell\n",
    "        self.bidirectional = bidirectional\n",
    "        self.dropout = dropout if num_layers > 1 else 0        # dropout rate\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.input_size, \n",
    "            hidden_size=self.hidden_size, \n",
    "            num_layers=self.num_layers, \n",
    "            dropout=self.dropout,\n",
    "            bidirectional=self.bidirectional,\n",
    "            batch_first=True)\n",
    "        \n",
    "        self.dummy_param = nn.Parameter(torch.zeros(1), requires_grad=False)\n",
    "\n",
    "    def forward(self, *args):\n",
    "        \"\"\"compute BiLSTM\n",
    "\n",
    "        Args:\n",
    "            x (*Any): input directly to pytorch LSTM\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        # h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)\n",
    "        # c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        out, (h, c) = self.lstm(*args) # output of size (B, T, D * hidden_size), where D = 1 if not bidirectional else 2; h and c are of size (num_layers * D, B, hidden_size)\n",
    "\n",
    "        return out, (h, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from collections.abc import Callable\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class BiAffine(nn.Module):\n",
    "    def __init__(self, num_classes: int, enc_input_size: int, dec_input_size: int, include_attention=False, check_accuracy: bool=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.enc_input_size = enc_input_size\n",
    "        self.dec_input_size = dec_input_size\n",
    "\n",
    "        self.Z = nn.Parameter(torch.zeros(self.num_classes, self.dec_input_size, self.enc_input_size), requires_grad=True)\n",
    "        self.b = nn.Parameter(torch.zeros(self.num_classes), requires_grad=True)\n",
    "        self.U_enc = nn.Parameter(torch.zeros(self.num_classes, self.enc_input_size), requires_grad=True)\n",
    "        self.U_dec = nn.Parameter(torch.zeros(self.num_classes, self.dec_input_size), requires_grad=True)\n",
    "\n",
    "        self.include_attention = include_attention\n",
    "        self.w = None\n",
    "        if self.include_attention:\n",
    "            self.w = nn.Parameter(torch.zeros(self.num_classes), requires_grad=True)\n",
    "\n",
    "        self.check_accuracy = check_accuracy\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def forward(self, enc: torch.Tensor, dec: torch.Tensor):\n",
    "        \"\"\"calculate biaffine score between enc and dec\n",
    "\n",
    "        Args:\n",
    "            enc (torch.Tensor): tensor of size (B, T, enc_input_size)\n",
    "            dec (torch.Tensor): tensor of size (B, T, dec_input_size)\n",
    "        \"\"\"\n",
    "\n",
    "        dec_brd = dec[:, :, None, None, :, None]         # (B, T, 1,     1,           dec_input_size, 1)\n",
    "        Z = self.Z[None, None, None, :, :, :]            # (1, 1, 1,     num_classes, dec_input_size, enc_input_size)\n",
    "        enc_brd = enc[:, None, :, None, :, None]         # (B, 1, T + 1, 1,           enc_input_size, 1)\n",
    "\n",
    "        interaction_score = (dec_brd.transpose(-1, -2) @ Z @ enc_brd).squeeze(-1, -2) # (B, T, T + 1, num_classes) index via [batch_number, DECoder_index, ENCoder_index]\n",
    "\n",
    "        dec_brd = dec_brd.squeeze(3)\n",
    "        enc_brd = enc_brd.squeeze(3)\n",
    "\n",
    "        enc_score = (self.U_enc @ enc_brd).squeeze(-1) # (B, 1, T + 1, num_classes)\n",
    "        dec_score = (self.U_dec @ dec_brd).squeeze(-1) # (B, T, 1, num_classes)\n",
    "\n",
    "        bias = self.b[None, None, None, :]             # (1, 1, 1, num_classes)\n",
    "\n",
    "        res = interaction_score + enc_score + dec_score + bias\n",
    "\n",
    "        # check correctness\n",
    "        if self.check_accuracy:\n",
    "            n_batches = enc.shape[0]\n",
    "            seq_length = dec.shape[1]\n",
    "            assert enc.shape[1] == seq_length + 1, \"Encoder output must have one more item than decoder, as the first item denotes ROOT\"\n",
    "\n",
    "            for batch_num in range(n_batches):\n",
    "                for c in range(self.num_classes):\n",
    "                    for i in range(seq_length + 1): # encoder index\n",
    "                        for j in range(seq_length): # decoder index\n",
    "                            res_val = res[batch_num, j, i, c]\n",
    "\n",
    "                            true_val = dec[batch_num, j] @ self.Z[c] @ enc[batch_num, i] + self.U_enc[c] @ enc[batch_num, i] + self.U_dec[c] @ dec[batch_num, j] + self.b[c]\n",
    "                        \n",
    "                            print((res_val.item() - true_val.item()) / true_val.item())\n",
    "\n",
    "        if self.include_attention:\n",
    "            res = self.w @ res.tanh().transpose(-1, -2) # (B, T, T + 1)\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        with torch.no_grad():\n",
    "            Zb_bound = ((self.enc_input_size ** 0.5) * (self.dec_input_size ** 0.5)) ** 0.5\n",
    "            self.Z.uniform_(-Zb_bound, Zb_bound)\n",
    "            self.b.uniform_(-Zb_bound, Zb_bound)\n",
    "\n",
    "            U_enc_bound = self.enc_input_size ** 0.5\n",
    "            self.U_enc.uniform_(-U_enc_bound, U_enc_bound)\n",
    "            U_dec_bound = self.dec_input_size ** 0.5\n",
    "            self.U_dec.uniform_(-U_dec_bound, U_dec_bound)\n",
    "\n",
    "            if self.include_attention:\n",
    "                w_bound = self.num_classes ** 0.5\n",
    "                self.w.uniform_(-w_bound, w_bound)\n",
    "\n",
    "class TigerModel(nn.Module):\n",
    "    class WordEmbeddingParams(BaseModel):\n",
    "        char_set: dict[str, int]\n",
    "        char_flag_generators: list[Callable[[str], Literal[1, 0]]]\n",
    "        char_internal_embedding_dim: int\n",
    "        char_part_embedding_dim: int\n",
    "        word_part_embedding_dim: int\n",
    "        char_internal_window_size: int\n",
    "        word_dict: dict[int, str]\n",
    "\n",
    "    class LSTMParams(BaseModel):\n",
    "        hidden_size: int\n",
    "        bidirectional: bool = Field(default=False)\n",
    "        num_layers: int = Field(default=1)\n",
    "        dropout: float = Field(default=0.2)\n",
    "\n",
    "    def __init__(self, word_embedding_params: WordEmbeddingParams, enc_lstm_params: LSTMParams, dec_lstm_params: LSTMParams, num_biaffine_attention_classes=2, num_constituent_labels=10):\n",
    "        super().__init__()\n",
    "        self.dummy_param = nn.Parameter(torch.zeros(1), requires_grad=False) # to get self device\n",
    "        \n",
    "        # create word embeddor\n",
    "        self.word_embedding_params = word_embedding_params\n",
    "        self.word_embedding = WordEmbedding(\n",
    "            char_set=self.word_embedding_params.char_set,\n",
    "            char_flag_generators=self.word_embedding_params.char_flag_generators,\n",
    "            char_internal_embedding_dim=self.word_embedding_params.char_internal_embedding_dim,\n",
    "            char_part_embedding_dim=self.word_embedding_params.char_part_embedding_dim,\n",
    "            word_part_embedding_dim=self.word_embedding_params.word_part_embedding_dim,\n",
    "            char_internal_window_size=self.word_embedding_params.char_internal_window_size,\n",
    "            word_dict=self.word_embedding_params.word_dict\n",
    "        )\n",
    "\n",
    "        # define encoder\n",
    "        self.enc_lstm_params = enc_lstm_params\n",
    "        assert enc_lstm_params.bidirectional == True, \"Encoder must be bidirectional\"\n",
    "        self.enc_lstm = LSTM(\n",
    "            input_size=word_embedding_params.char_part_embedding_dim + word_embedding_params.word_part_embedding_dim,\n",
    "            hidden_size=self.enc_lstm_params.hidden_size,\n",
    "            num_layers=self.enc_lstm_params.num_layers,\n",
    "            bidirectional=self.enc_lstm_params.bidirectional,\n",
    "            dropout=self.enc_lstm_params.dropout\n",
    "        )\n",
    "\n",
    "        # define decoder\n",
    "        self.dec_lstm_params = dec_lstm_params\n",
    "        assert self.dec_lstm_params.bidirectional == False, \"Decoder must not be bidirectional\"\n",
    "        self.dec_lstm = LSTM(\n",
    "            input_size=2 * self.enc_lstm_params.hidden_size,\n",
    "            hidden_size=self.dec_lstm_params.hidden_size,\n",
    "            num_layers=self.dec_lstm_params.num_layers,\n",
    "            bidirectional=self.dec_lstm_params.bidirectional,\n",
    "            dropout=self.dec_lstm_params.dropout\n",
    "        )\n",
    "\n",
    "        # define initial encoder state\n",
    "        self.enc_init_state = nn.Parameter(\n",
    "            torch.zeros(2 * self.enc_lstm_params.num_layers, 1, self.enc_lstm_params.hidden_size),\n",
    "            requires_grad=True\n",
    "        )\n",
    "\n",
    "        # define dense layer to convert encoder final cell state into decoder initial cell state\n",
    "        self.enc_final_cell_to_dec_init_cell = nn.Linear(\n",
    "            2 * self.enc_lstm_params.hidden_size,\n",
    "            self.dec_lstm_params.hidden_size\n",
    "        )\n",
    "\n",
    "        # define biaffine layer for attention\n",
    "        self.biaffine_attention = BiAffine(\n",
    "            num_classes=num_biaffine_attention_classes,\n",
    "            enc_input_size=2 * self.enc_lstm_params.hidden_size,\n",
    "            dec_input_size=self.dec_lstm_params.hidden_size,\n",
    "            include_attention=True\n",
    "        )\n",
    "\n",
    "        # define biaffine layer for classification of constituent labels\n",
    "        self.biaffine_constituent_classifier = BiAffine(\n",
    "            num_classes=num_constituent_labels,\n",
    "            enc_input_size=2 * self.enc_lstm_params.hidden_size,\n",
    "            dec_input_size=self.dec_lstm_params.hidden_size,\n",
    "            include_attention=False\n",
    "        )\n",
    "\n",
    "    def _get_final_concatenated_enc_hidden_state(self, c: torch.Tensor):\n",
    "        \"\"\"takes final two layers of final cell state of encoder and returns a tensor of size (B, 1, 2 * enc_hidden_size) to initialise the decoder (or encoder)\n",
    "\n",
    "        Args:\n",
    "            c (torch.Tensor): final cell state or hidden state, of size (enc_num_layers * 2, B, enc_hidden_size)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: last two layers of the state concatenated together. size (B, 1, 2 * enc_hidden_size)\n",
    "        \"\"\"\n",
    "        _, B, _ = c.shape\n",
    "        res = c[-2:] # take the last two layers (2, B, enc_hidden_size)\n",
    "        res = res.transpose(0, 1).contiguous() # (B, 2, enc_hidden_size)\n",
    "        res = res.view(B, 1, 2 * self.enc_lstm_params.hidden_size) # (B, 1, 2 * enc_hidden_size)\n",
    "        return res\n",
    "\n",
    "    def _get_decoder_init_state(self, encoder_final_hc: tuple[torch.Tensor, torch.Tensor]):\n",
    "        \"\"\"convert final encoder hidden state into a value to initialise hidden state for the decoder\n",
    "\n",
    "        Args:\n",
    "            encoder_final_hc (tuple[torch.Tensor, torch.Tensor]): tuple of tensors, each with size (enc_num_layers * 2, B, enc_hidden_size)\n",
    "\n",
    "        returns tuple[torch.Tensor, torch.Tensor]: tuple of initial decoder state tensors, each with size (dec_num_layers, B, dec_hidden_size). First is initial hidden state, second is inital cell state for the decoder\n",
    "        \"\"\"\n",
    "        h, c = encoder_final_hc\n",
    "        _, B, _ = h.shape\n",
    "\n",
    "        c = self._get_final_concatenated_enc_hidden_state(c)\n",
    "        c = c.transpose(0, 1) # (1, B, 2 * enc_hidden_size)\n",
    "        \n",
    "        c_dec: torch.Tensor = self.enc_final_cell_to_dec_init_cell(c) # (1, B, dec_hidden_size)\n",
    "        if self.dec_lstm_params.num_layers > 1:\n",
    "            c_dec = torch.cat([c_dec, c_dec.new_zeros((self.dec_lstm_params.num_layers - 1, B, self.dec_lstm.hidden_size))], dim=0)\n",
    "        \n",
    "        h_dec = c_dec.tanh()\n",
    "\n",
    "        return (h_dec, c_dec)\n",
    "        \n",
    "\n",
    "    def forward(self, input: tuple[torch.Tensor, torch.Tensor], new_words_dict: dict[int, str] | None):\n",
    "        \"\"\"forward\n",
    "\n",
    "        Args:\n",
    "            input (tuple[torch.Tensor, torch.Tensor]): tuple of (data, sentence_lengths), where data is a tensor of size (B, T) and sentence_lengths is a tensor of size (B,). B is batch size, T is max(sentence_length) across all batches. The input must be sorted in descending order of sentence length\n",
    "            new_words_dict (dict[int, str] | None): dictionary of new words. positive indices in new_words_dict correspond to negative indices in input[0] (data). If None, then all unknown words must be coded as 0\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "\n",
    "        # transfer to current device. avoid making a copy if possible\n",
    "        x, lengths = input     \n",
    "        x = torch.as_tensor(x, device=self.dummy_param.device)\n",
    "\n",
    "        B = len(lengths)\n",
    "\n",
    "        # create packed embedding sequences\n",
    "        x_embedded = self.word_embedding(x, new_words_dict) # (B, T, E) where B is batch_size, T is max(sentence_length), E is embedding dimension (char_part_embedding_dim + word_part_embedding_dim)\n",
    "        x_embedded_packed = rnn_utils.pack_padded_sequence(x_embedded, lengths, batch_first=True, enforce_sorted=True)\n",
    "\n",
    "        # henceforth, T refers to max(sentence_length) within the batch, rather than across all batches\n",
    "\n",
    "        # define initial encoder state\n",
    "        c_init = self.enc_init_state.repeat(1, B, 1) # (enc_num_layers * 2, B, enc_hidden_size)\n",
    "        h_init = c_init.tanh()\n",
    "\n",
    "        # feed through encoder\n",
    "        enc_out, enc_final_state = self.enc_lstm(x_embedded_packed, (h_init, c_init)) # enc_out has size (B, T, 2 * enc_hidden_size)  \n",
    "        enc_out_pad, _ = rnn_utils.pad_packed_sequence(enc_out, batch_first=True)\n",
    "\n",
    "        # feed through decoder\n",
    "        dec_init_state = self._get_decoder_init_state(enc_final_state) # tuple of tensors, each with size (dec_num_layers, B, dec_hidden_size)\n",
    "        dec_out, _ = self.dec_lstm(enc_out, (dec_init_state[0], dec_init_state[1])) # (B, T, hidden_size)\n",
    "\n",
    "        # TODO: apply dropout to enc_out\n",
    "\n",
    "        # unpad encoder output (B, T + 1, 2 * enc_hidden_size)\n",
    "        # concatenate final layer of initial encoder state with the output of the encoder\n",
    "        h_init_res = self._get_final_concatenated_enc_hidden_state(h_init) # (B, 1, 2 * enc_hidden_size)\n",
    "        enc_out_pad = torch.cat((h_init_res, enc_out_pad), dim=1) # (B, T + 1, 2 * enc_hidden_size)\n",
    "\n",
    "        # unpad decoder output (B, T, hidden_size)\n",
    "        dec_out_pad, _ = rnn_utils.pad_packed_sequence(dec_out, batch_first=True)\n",
    "\n",
    "        # henceforth, indices are 0-indexed in the comments. Effectively, head indices are 1-indexed (0 indicates root), and dependency indices are 0-indexed\n",
    "        # TASK 1: predict HEAD words\n",
    "        # for batch b and word index j, argmax(self_attention[b, j]) gives a pointer i to HEAD of word j\n",
    "        self_attention = self.biaffine_attention(enc_out_pad, dec_out_pad) # size (B, T, T + 1). index by (batch_num, decoder_index, encoder_index + 1), which represents (batch_num, dependency_index, head_index + 1)\n",
    "\n",
    "        # TASK 2: predict ATTACHMENT labels\n",
    "        # for batch b and dependency index j and head index i, constituent_lables[b, j, i] gives logits to classify the label of the dependency from word j to HEAD word i\n",
    "        constituent_labels = self.biaffine_constituent_classifier(enc_out_pad, dec_out_pad) # size (B, T, T + 1, num_constituent_labels). index by (batch_num, decoder_index, encoder_index + 1, label_index), which represents (batch_num, dependency_index, head_index + 1, label_index)\n",
    "\n",
    "        # TASK 3: predict attachment ORDER\n",
    "\n",
    "        self._mask_out(self_attention, lengths)\n",
    "        self._mask_out(constituent_labels, lengths)\n",
    "\n",
    "        # TODO: TASK 4: predict DEPENDENCY labels (according to GM 2022, this will improve overall performance in a multitask setting)\n",
    "\n",
    "        indices = self._get_batch_indices(lengths)\n",
    "\n",
    "        return self_attention, constituent_labels, indices\n",
    "\n",
    "    def _mask_out(self, out: torch.Tensor, lengths: torch.Tensor):\n",
    "        \"\"\"mask out unneeded output elements IN PLACE, given sentence lengths\n",
    "\n",
    "        Args:\n",
    "            out (torch.Tensor): size (B, T, T + 1)\n",
    "            lengths (torch.Tensor): sorted tensor in descending order where len(lengths) = B and lengths[0] = T\n",
    "        \"\"\"\n",
    "        B, T, *_ = out.shape\n",
    "        dependency_index_mask = torch.triu(torch.full((T + 1, T), True))[lengths].unsqueeze(-1).repeat(1, 1, T + 1) # (B, T, T + 1)\n",
    "        out[dependency_index_mask] = -torch.inf\n",
    "\n",
    "        head_index_mask = torch.triu(torch.full((T + 2, T + 1), True))[lengths + 1].unsqueeze(-2).repeat(1, T, 1) # (B, T, T + 1)\n",
    "        out[head_index_mask] = -torch.inf\n",
    "\n",
    "    def _get_batch_indices(self, lengths: torch.Tensor):\n",
    "        \"\"\"Get indices for a given set of sentence lengths.\n",
    "           Suppose x is a tensor of size (B, T, *), which has been masked out\n",
    "           Some elements of x are not needed, as they correspond to padding. This function returns the indices of the elements that are needed\n",
    "           x[indices] will give you a tensor of size (N, *)\n",
    "\n",
    "        Args:\n",
    "            lengths (torch.Tensor): sorted tensor in descending order where len(lengths) = B and lengths[0] = T, the longest sentence _within the batch_\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: indices of size (N, *) where each row is non-masked\n",
    "        \"\"\"\n",
    "\n",
    "        T = lengths[0].item() # max sentence length within batch\n",
    "        indices = ~torch.triu(torch.full((T + 1, T), True))[lengths] # type: ignore\n",
    "        return indices\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = TigerModel(TigerModel.WordEmbeddingParams(char_set=g.character_set, char_flag_generators=g.character_flag_generators, char_internal_embedding_dim=10, char_part_embedding_dim=10, word_part_embedding_dim=10, char_internal_window_size=3, word_dict=g.inverse_word_dict), TigerModel.LSTMParams(hidden_size=10, bidirectional=True), TigerModel.LSTMParams(hidden_size=10, bidirectional=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_attention, labels, indices = m((input[0], input[1]), train_dataset.get_new_words_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = input[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([40, 34, 34, 33, 29, 29, 27, 25, 23, 23, 22, 22, 21, 20, 19, 18, 17, 16,\n",
       "        16, 15, 15, 13, 12, 11, 11, 10, 10,  9,  8,  6,  3,  2])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.cross_entropy(self_attention[indices], input[2][:,0:T][indices]).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "german",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
