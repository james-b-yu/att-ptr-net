{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLinear(nn.Module):\n",
    "    letters = \"abcdefghijklmopqrstuvwxyz\" # all letters except n\n",
    "\n",
    "    def _index_generator(self, num_indices_to_skip=0):\n",
    "        for c in (self.available_indexing_names[num_indices_to_skip:]):\n",
    "            yield c\n",
    "\n",
    "    def __init__(self, N: int, *S: int):\n",
    "        \"\"\"class for computing a linear transformation between $M$ vectors, where vector i lives in S[i]-dimensional space\n",
    "        Args:\n",
    "            N (int): the dimension of the output\n",
    "            *S (int): the dimensions of the inputs. Should be of length $M$\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.S = S\n",
    "        self.M = len(S)\n",
    "        self.N = N\n",
    "\n",
    "        self.Z = nn.Parameter(torch.zeros(N, *S)) # (N, S_{1}, ..., S_{M})\n",
    "\n",
    "        self.summing_names = self.letters[-self.M:]\n",
    "        self.available_indexing_names = self.letters[:-self.M]\n",
    "\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.Z)\n",
    "\n",
    "    def forward(self, *X: torch.Tensor, num_batch_dims=0):\n",
    "        \"\"\"compute linear transformation given the M tensors in N\n",
    "        Args:\n",
    "            *X (torch.Tensor): sequence of M tensors, where X[i].shape[-1] == S[i]\n",
    "        Returns:\n",
    "            torch.Tensor: _description_\n",
    "        \"\"\"\n",
    "        total_indexing_dim = sum(map(lambda x: x.dim() - 1 - num_batch_dims, X))\n",
    "        i_gen = self._index_generator(num_batch_dims)\n",
    "\n",
    "        batch_indexing_names = self.available_indexing_names[:num_batch_dims]\n",
    "\n",
    "        z_indices = \"n\" + self.summing_names\n",
    "        x_indices = \",\".join([batch_indexing_names + \"\".join([next(i_gen) for j in range(m.dim() - 1 - num_batch_dims)]) + self.summing_names[i] for i, m in enumerate(X)])\n",
    "        r_indices = batch_indexing_names + self.available_indexing_names[num_batch_dims:num_batch_dims + total_indexing_dim] + \"n\"\n",
    "\n",
    "        return torch.einsum(f\"{z_indices},{x_indices}->{r_indices}\", self.Z, *X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "class MAffine(nn.Module):\n",
    "    @classmethod\n",
    "    def _combinations(cls, n, c):\n",
    "        # Initialize the first combination (lexicographically smallest)\n",
    "        combination = torch.arange(c)\n",
    "\n",
    "        while combination[0] < n - c + 1:\n",
    "            yield combination\n",
    "\n",
    "            # Find the rightmost element that can be incremented\n",
    "            j = c - 1\n",
    "            while j >= 0 and combination[j] == n - c + j:\n",
    "                j -= 1\n",
    "\n",
    "            # Increment the rightmost element that can be incremented\n",
    "            combination[j] += 1\n",
    "\n",
    "            # Adjust the elements to the right\n",
    "            for k in range(j + 1, c):\n",
    "                combination[k] = combination[k - 1] + 1\n",
    "\n",
    "    def __init__(self, N: int, *S: int):\n",
    "        \"\"\"class for computing an affine transformation between $M$ vectors, where vector i lives in S[i]-dimensional space\n",
    "        Args:\n",
    "            N (int): the dimension of the output\n",
    "            *S (int): the dimensions of the inputs. Should be of length $M$\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.S = torch.tensor(S, dtype=torch.long)\n",
    "        self.M = len(S)\n",
    "        self.N = N\n",
    "        \n",
    "        self.b = nn.Parameter(torch.zeros(self.N)) # the bias term\n",
    "\n",
    "        self.linears = nn.ModuleList()\n",
    "\n",
    "        for k in range(1, self.M + 1):\n",
    "            for comb in self._combinations(self.M, k):\n",
    "                S_subset = self.S.gather(index=comb, dim=-1)\n",
    "                self.linears.append(MLinear(self.N, *S_subset.numpy()))\n",
    "\n",
    "    def forward(self, *X: torch.Tensor, num_batch_dims=0):\n",
    "        assert len(X) == self.M\n",
    "\n",
    "        indexing_dims = torch.tensor([num_batch_dims, *map(lambda x: len(x.shape) - 1 - num_batch_dims, X)], dtype=torch.long)\n",
    "        indexing_dims_cum = indexing_dims.cumsum(dim=0)\n",
    "\n",
    "        total_indexing_dims = int(indexing_dims_cum[-1])\n",
    "\n",
    "        tensor_indices = torch.zeros(self.M, total_indexing_dims + 1, dtype=torch.long) # M[i, j] != 0 if in the result, the jth index corresponds to one of the indices we used to index tensor i. M[i, j] is the size of the jth dimension in the final result\n",
    "        \n",
    "        helper = torch.full((total_indexing_dims + 1, total_indexing_dims + 1), True).tril(diagonal=-1)\n",
    "\n",
    "        tensor_indices_sizes = torch.tensor(reduce(lambda a, b: a + b.shape[num_batch_dims:-1], X, X[0].shape[:num_batch_dims]) + (self.N,), dtype=torch.long)\n",
    "\n",
    "        tensor_indices[helper[indexing_dims_cum[1:]]] = 1\n",
    "        tensor_indices[helper[indexing_dims_cum[:-1]]] = 0\n",
    "        tensor_indices[:, -1] = 1 # final position of output tensor always corresponds to the self.N classes\n",
    "        tensor_indices[:, :num_batch_dims] = 1 # initial positions of output tensor always correspond to the num_batch_indices\n",
    "\n",
    "        lin_iter = iter(self.linears)\n",
    "\n",
    "        all_pre_broadcast: list[torch.Tensor] = []\n",
    "\n",
    "        for k in range(1, self.M + 1):\n",
    "            for comb in self._combinations(self.M, k):\n",
    "                S_subset = self.S.gather(index=comb, dim=-1)\n",
    "                inputs = [X[int(i)] for i in comb]\n",
    "\n",
    "                model: MLinear = next(lin_iter) #type:ignore\n",
    "\n",
    "                res: torch.Tensor = model(*inputs, num_batch_dims=num_batch_dims)\n",
    "                res_positions = tensor_indices[comb].any(dim=0) # v[i] = 1 if res's indices should correspond to the ith index of final output\n",
    "                res_layout = tensor_indices_sizes.clone()\n",
    "\n",
    "                res_layout[~res_positions] = 1\n",
    "\n",
    "                res_pre_broadcast = res.view(*res_layout.numpy())\n",
    "                all_pre_broadcast.append(res_pre_broadcast)\n",
    "                pass\n",
    "\n",
    "        return sum(all_pre_broadcast) + self.b.view([1] * total_indexing_dims + [self.N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = MLinear(10, 30, 31, 50, 50).cuda()\n",
    "b_size = 128\n",
    "i1, i2, i3, i4 = torch.randn(b_size, 3, 30), torch.randn(b_size, 3, 31), torch.randn(b_size, 3, 50), torch.randn(b_size, 3, 50)\n",
    "inputs = [i1, i2, i3, i4]\n",
    "inputs_cuda = [input.cuda() for input in inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "german",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
